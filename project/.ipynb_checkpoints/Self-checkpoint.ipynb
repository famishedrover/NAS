{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed('Mudit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPERIMENTS -- Morphism Type I\n",
    "\n",
    "<img src=\"images/morph1.png\" width=700>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        \"\"\"\n",
    "        In the constructor we construct three nn.Linear instances that we will use\n",
    "        in the forward pass.\n",
    "        \"\"\"\n",
    "        super(Net, self).__init__()\n",
    "        self.inp = D_in\n",
    "        self.out = D_out\n",
    "        self.input_linear = torch.nn.Linear(D_in, H)\n",
    "        self.middle_linear = torch.nn.Linear(H, H)\n",
    "        self.output_linear = torch.nn.Linear(H, D_out)\n",
    "        self.layers = [self.input_linear, self.middle_linear,self.output_linear] \n",
    "        \n",
    "        \n",
    "    \n",
    "    def add_layer(self,pos) :\n",
    "        #insert after pos\n",
    "        #patchwork\n",
    "        #pass from x to pos-1 to get output shape\n",
    "        tempx = torch.randn(1, self.inp)\n",
    "        resx = self.forward(tempx,pause=pos)\n",
    "        print resx.shape\n",
    "        #create pos shaped layer\n",
    "        templayer = torch.nn.Linear(resx.shape[-1],resx.shape[-1])\n",
    "        self.layers.insert(pos,templayer)\n",
    "        \n",
    "        #call for update params\n",
    "\n",
    "   \n",
    "    def forward(self, x,pause=-1):\n",
    "        print 'Layers :',len(self.layers)\n",
    "        \n",
    "        cnt = 0\n",
    "        out = self.layers[0](x)\n",
    "        cnt += 1\n",
    "        if(pause == 1):\n",
    "            return out\n",
    "        \n",
    "        \n",
    "        counter = 1\n",
    "        for layer in self.layers[1:] :\n",
    "            counter+=1\n",
    "            cnt += 1\n",
    "            out = layer(out)\n",
    "            if pause != -1 :\n",
    "                if(counter==pause) :\n",
    "                    print 'Count of Layers = ',cnt\n",
    "                    return out\n",
    "            print 'Count of Layers = ',cnt\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Attempt is to change optimizer dynamically\n",
    "\n",
    "2. Criterion failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers : 3\n",
      "Count of Layers =  2\n",
      "Count of Layers =  3\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1               [-1, 1, 100]         100,100\n",
      "            Linear-2               [-1, 1, 100]          10,100\n",
      "            Linear-3                [-1, 1, 10]           1,010\n",
      "================================================================\n",
      "Total params: 111,210\n",
      "Trainable params: 111,210\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.42\n",
      "Estimated Total Size (MB): 0.43\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = Net(D_in, H, D_out)\n",
    "summary(model,(1,D_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers : 3\n",
      "Count of Layers =  2\n",
      "torch.Size([1, 100])\n",
      "Layers : 4\n",
      "Count of Layers =  2\n",
      "Count of Layers =  3\n",
      "Count of Layers =  4\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1               [-1, 1, 100]         100,100\n",
      "            Linear-2               [-1, 1, 100]          10,100\n",
      "            Linear-3                [-1, 1, 10]           1,010\n",
      "================================================================\n",
      "Total params: 111,210\n",
      "Trainable params: 111,210\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.42\n",
      "Estimated Total Size (MB): 0.43\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.add_layer(2)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9) \n",
    "summary(model,(1,D_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Linear(in_features=1000, out_features=100, bias=True),\n",
       " Linear(in_features=100, out_features=100, bias=True),\n",
       " Linear(in_features=100, out_features=100, bias=True),\n",
       " Linear(in_features=100, out_features=10, bias=True)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers : 3\n",
      "Count of Layers =  2\n",
      "Count of Layers =  3\n",
      "(0, 675.8677368164062)\n",
      "Layers : 3\n",
      "Count of Layers =  2\n",
      "Count of Layers =  3\n",
      "(1, 638.0596923828125)\n",
      "Layers : 3\n",
      "Count of Layers =  2\n",
      "Count of Layers =  3\n",
      "(2, 572.4498291015625)\n",
      "Layers : 3\n",
      "Count of Layers =  2\n",
      "Count of Layers =  3\n",
      "(3, 490.211669921875)\n",
      "Layers : 3\n",
      "Count of Layers =  2\n",
      "Count of Layers =  3\n",
      "(4, 400.2493591308594)\n",
      "Layers : 3\n",
      "Count of Layers =  2\n",
      "Count of Layers =  3\n",
      "(5, 308.8610534667969)\n",
      "New optim at work\n",
      "Layers : 3\n",
      "Count of Layers =  2\n",
      "Count of Layers =  3\n",
      "(6, 298.4310302734375)\n",
      "Layers : 3\n",
      "Count of Layers =  2\n",
      "Count of Layers =  3\n",
      "(7, 288.119384765625)\n",
      "Layers : 3\n",
      "Count of Layers =  2\n",
      "Count of Layers =  3\n",
      "(8, 277.9320373535156)\n",
      "Layers : 3\n",
      "Count of Layers =  2\n",
      "Count of Layers =  3\n",
      "(9, 267.874755859375)\n"
     ]
    }
   ],
   "source": [
    "model = Net(D_in, H, D_out)\n",
    "\n",
    "\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)\n",
    "\n",
    "num = 10\n",
    "for t in range(num):\n",
    "    y_pred = model(x)\n",
    "    loss = criterion(y_pred, y)\n",
    "    print(t, loss.item())\n",
    "    \n",
    "    if(t==num/2) :\n",
    "        optimizer = torch.optim.Adam(model.parameters(),lr=1e-4)\n",
    "        # with NLL gives certain Long/Float err\n",
    "        print 'New optim at work'\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers : 3\n",
      "Count of Layers =  2\n",
      "Count of Layers =  3\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1               [-1, 1, 100]         100,100\n",
      "            Linear-2               [-1, 1, 100]          10,100\n",
      "            Linear-3                [-1, 1, 10]           1,010\n",
      "================================================================\n",
      "Total params: 111,210\n",
      "Trainable params: 111,210\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.42\n",
      "Estimated Total Size (MB): 0.43\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model,(1,D_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1000])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100])\n",
      "torch.Size([10, 100])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for e in model.parameters() :\n",
    "    print e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Linear(in_features=1000, out_features=100, bias=True),\n",
       " Linear(in_features=100, out_features=100, bias=True),\n",
       " Linear(in_features=100, out_features=10, bias=True)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-68ef22944adf>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-68ef22944adf>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    m = nn.Sequential(for x in model.layers[:pos],nn.Linear(sz,sz),for x in model.layers[pos:])\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pos = 2\n",
    "sz = model.forward([1,D_in]).shape[-1]\n",
    "m = nn.Sequential(for x in model.layers[:pos],nn.Linear(sz,sz),for x in model.layers[pos:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Sequential?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nnet(nn.Module) :\n",
    "    def __init__(self,inp,out) :\n",
    "        super(nnet, self).__init__()\n",
    "        self.fc1 = nn.Linear(inp,64)\n",
    "        self.fc2 = nn.Linear(64,128)\n",
    "        self.fc3 = nn.Linear(128,32)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.fc3(self.fc2(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nnet(16,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = model(x)\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc1.out_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc2 = nn.Sequential(nn.Linear(model.fc1.out_features,model.fc1.out_features),model.fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nnet(\n",
       "  (fc1): Linear(in_features=16, out_features=64, bias=True)\n",
       "  (fc2): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (1): Linear(in_features=64, out_features=128, bias=True)\n",
       "  )\n",
       "  (fc3): Linear(in_features=128, out_features=32, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc2[1] = nn.Sequential(model.fc2[1],nn.Linear(model.fc2[1].out_features,model.fc2[1].out_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nnet(\n",
       "  (fc1): Linear(in_features=16, out_features=64, bias=True)\n",
       "  (fc2): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=128, bias=True)\n",
       "      (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (fc3): Linear(in_features=128, out_features=32, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                [-1, 1, 64]           1,088\n",
      "            Linear-2                [-1, 1, 64]           4,160\n",
      "            Linear-3               [-1, 1, 128]           8,320\n",
      "            Linear-4               [-1, 1, 128]          16,512\n",
      "            Linear-5                [-1, 1, 32]           4,128\n",
      "================================================================\n",
      "Total params: 34,208\n",
      "Trainable params: 34,208\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.13\n",
      "Estimated Total Size (MB): 0.13\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model,(1,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc2[0].out_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mechanism required to map all the layers, some sort of dict to call each layer may be stored there itself. We can add a final layer to pytorch module this way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2 -- Network Morph II\n",
    "<img src=\"images/morph2.png\" width=700>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/possible-to-add-initialize-new-nodes-to-hidden-layer-partway-through-training/3809/2\n",
    "# https://github.com/mortezamg63/Accessing-and-modifying-different-layers-of-a-pretrained-model-in-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, layer_size, hidden, input_size, output_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.layer_size = layer_size\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.device = 'cpu'\n",
    "\n",
    "        # initialize weights\n",
    "        self.fcs = nn.ModuleList([nn.Linear(self.input_size, self.layer_size)])\n",
    "        self.fcs.append(nn.Linear(self.layer_size, self.output_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        print 'Forward...'\n",
    "        print 'X:',x.shape\n",
    "        print 'weight shapes...'\n",
    "        print 'fcs-0:',self.fcs[0].weight.shape\n",
    "        print 'fcs-1:',self.fcs[1].weight.shape\n",
    "        print 'goes in ', self.fcs[0], 'and gives out'\n",
    "        out = self.fcs[0](x)\n",
    "        print 'out-0:',out.shape, 'and will go in'\n",
    "#         print self.fcs[1]\n",
    "        out = self.fcs[1](out)\n",
    "        print 'out-2:', out.shape\n",
    "#         return self.fcs[1](self.fcs[0](x))\n",
    "    \n",
    "    def add_units(self, addneurons):\n",
    "        # take a copy of the current weights stored in self.fcs\n",
    "        current = [ix.weight.data for ix in self.fcs]\n",
    "        print 'Current:',len(current), ' 1:',current[0].shape,' 2:',current[1].shape\n",
    "\n",
    "        # make the new weights in and out of hidden layer you are adding neurons to\n",
    "        tmp_i = torch.zeros([addneurons, current[0].shape[1]])\n",
    "        print 'tmp_i:',tmp_i.shape\n",
    "        nn.init.xavier_uniform_(tmp_i, gain=nn.init.calculate_gain('relu'))\n",
    "        tmp_o = torch.zeros([current[1].shape[0], addneurons])\n",
    "        print 'tmp_o:',tmp_o.shape\n",
    "        nn.init.xavier_uniform_(tmp_i, gain=nn.init.calculate_gain('relu'))\n",
    "\n",
    "        # concatenate the old weights with the new weights\n",
    "        new_wi = torch.cat([current[0], tmp_i], dim=0)\n",
    "        print 'new_wi:',new_wi.shape\n",
    "        new_wo = torch.cat([current[1], tmp_o], dim=1)\n",
    "        print 'new_wo:',new_wo.shape\n",
    "\n",
    "        # reset weight and grad variables to new size\n",
    "\n",
    "        #TODO------ Pl have a look!\n",
    "        \n",
    "        # should chnage self.layer_size to previous layer's neuron number \n",
    "        self.fcs[0] = nn.Linear(current[0].shape[1], self.layer_size+addneurons)\n",
    "        print 'fcs-0:',self.fcs[0]\n",
    "        self.fcs[1] = nn.Linear(addneurons+self.layer_size, current[1].shape[0])\n",
    "        print 'fcs-1:',self.fcs[1]\n",
    "        \n",
    "        \n",
    "#         self.fcs[0] = nn.Linear(current[0].shape[1], self.layer_size)\n",
    "#         print 'fcs-0:',self.fcs[0]\n",
    "#         self.fcs[1] = nn.Linear(self.layer_size, current[1].shape[0])\n",
    "#         print 'fcs-1:',self.fcs[1]\n",
    "\n",
    "        # set the weight data to new values\n",
    "        self.fcs[0].weight.data = torch.tensor(new_wi, requires_grad=True, device=self.device)\n",
    "        self.fcs[1].weight.data = torch.tensor(new_wo, requires_grad=True, device=self.device)\n",
    "        print 'self.fcs[0] and 1:',self.fcs[0].weight.shape, ' ', self.fcs[1].weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will be buggy when layers increased to 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "nm = Model(5,4,3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward...\n",
      "X: torch.Size([1, 3])\n",
      "weight shapes...\n",
      "fcs-0: torch.Size([5, 3])\n",
      "fcs-1: torch.Size([2, 5])\n",
      "goes in  Linear(in_features=3, out_features=5, bias=True) and gives out\n",
      "out-0: torch.Size([1, 5]) and will go in\n",
      "out-2: torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "nm(torch.randn(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current: 2  1: torch.Size([5, 3])  2: torch.Size([2, 5])\n",
      "tmp_i: torch.Size([7, 3])\n",
      "tmp_o: torch.Size([2, 7])\n",
      "new_wi: torch.Size([12, 3])\n",
      "new_wo: torch.Size([2, 12])\n",
      "fcs-0: Linear(in_features=3, out_features=12, bias=True)\n",
      "fcs-1: Linear(in_features=12, out_features=2, bias=True)\n",
      "self.fcs[0] and 1: torch.Size([12, 3])   torch.Size([2, 12])\n"
     ]
    }
   ],
   "source": [
    "nm.add_units(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward...\n",
      "X: torch.Size([1, 3])\n",
      "weight shapes...\n",
      "fcs-0: torch.Size([12, 3])\n",
      "fcs-1: torch.Size([2, 12])\n",
      "goes in  Linear(in_features=3, out_features=12, bias=True) and gives out\n",
      "out-0: torch.Size([1, 12]) and will go in\n",
      "out-2: torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "nm(torch.randn(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward...\n",
      "X: torch.Size([2, 1, 3])\n",
      "weight shapes...\n",
      "fcs-0: torch.Size([12, 3])\n",
      "fcs-1: torch.Size([2, 12])\n",
      "goes in  Linear(in_features=3, out_features=12, bias=True) and gives out\n",
      "out-0: torch.Size([2, 1, 12]) and will go in\n",
      "out-2: torch.Size([2, 1, 2])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                [-1, 1, 12]              48\n",
      "            Linear-2                 [-1, 1, 2]              26\n",
      "================================================================\n",
      "Total params: 74\n",
      "Trainable params: 74\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(nm,(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current: 2  1: torch.Size([12, 3])  2: torch.Size([2, 12])\n",
      "tmp_i: torch.Size([10, 3])\n",
      "tmp_o: torch.Size([2, 10])\n",
      "new_wi: torch.Size([22, 3])\n",
      "new_wo: torch.Size([2, 22])\n",
      "fcs-0: Linear(in_features=3, out_features=15, bias=True)\n",
      "fcs-1: Linear(in_features=15, out_features=2, bias=True)\n",
      "self.fcs[0] and 1: torch.Size([22, 3])   torch.Size([2, 22])\n"
     ]
    }
   ],
   "source": [
    "nm.add_units(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward...\n",
      "X: torch.Size([2, 1, 3])\n",
      "weight shapes...\n",
      "fcs-0: torch.Size([22, 3])\n",
      "fcs-1: torch.Size([2, 22])\n",
      "goes in  Linear(in_features=3, out_features=15, bias=True) and gives out\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (22) must match the existing size (15) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-7f57e2bb5c14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Error Reason listed in the class above, line 52\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/torchsummary/torchsummary.pyc\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# make a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# remove these hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-6d32fe2df529>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'fcs-1:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfcs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'goes in '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfcs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'and gives out'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfcs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'out-0:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'and will go in'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m#         print self.fcs[1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/torch/nn/modules/linear.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/torch/nn/functional.pyc\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (22) must match the existing size (15) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "# Error Reason listed in the class above, line 52\n",
    "summary(nm,(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU()\n",
      "ModuleList(\n",
      "  (0): Linear(in_features=3, out_features=15, bias=True)\n",
      "  (1): Linear(in_features=15, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for i in nm.children():\n",
    "    print i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up different learning rates for different layers\n",
    "\n",
    "Advancement over other archs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignored_params = list(map(id, model.fc.parameters()))\n",
    "# base_params = filter(lambda p: id(p) not in ignored_params,\n",
    "#                      model.parameters())\n",
    "\n",
    "# optimizer = torch.optim.SGD([\n",
    "#             {'params': base_params},\n",
    "#             {'params': model.fc.parameters(), 'lr': opt.lr}\n",
    "#         ], lr=opt.lr*0.1, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment -- Network Morphism - III\n",
    "<img src=\"images/morph3.png\" width=700>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read idempotent functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment -- Network Morphism IV\n",
    "<img src=\"images/morph4b.png\" width=700>\n",
    "<img src=\"images/morph4a.png\" width=700>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing h(x) is not trivial, atleast from first look."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing NASH\n",
    "\n",
    "<img src=\"images/algo.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total Training epochs => epoch_total = epoch_neigh.n_neigh.n_steps +epoch_final.\n",
    "\n",
    "With the setting \n",
    "\n",
    "n_steps =5\n",
    "\n",
    "epoch_neigh =17\n",
    "\n",
    "epoch_final =100\n",
    "\n",
    "and pretraining the starting network for 20 epochs, the models that are returned by the algorithm are trained for a total number of of 20 + 17 · 5 + 100 = 205 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some start model_0\n",
    "model_0 = 0\n",
    "n_steps = 10\n",
    "n_neigh = 4\n",
    "n_nm = 3\n",
    "epoch_neigh = 30\n",
    "epoch_final = 50\n",
    "lr_start = 0.01\n",
    "lr_end = 0.001  # annealed via SGDR\n",
    "\n",
    "model_best = model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'applyMorph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-ee1f9351a3d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# get n_neigh neighbours of model_best\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neigh\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mmodel_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapplyMorph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_best\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_nm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#train this model_j for a few epochs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'applyMorph' is not defined"
     ]
    }
   ],
   "source": [
    "# hill climbing\n",
    "\n",
    "for i in range(n_steps) :\n",
    "    \n",
    "    #NEIGHBOURS ---------------------\n",
    "    \n",
    "    # get n_neigh neighbours of model_best\n",
    "    for j in range(n_neigh-1) :\n",
    "        model_j = applyMorph(model_best,n_nm)\n",
    "        \n",
    "        #train this model_j for a few epochs.\n",
    "        \n",
    "        model_j = Train(SGDR,model_j,epoch_neigh,lr_start,lr_end)\n",
    "     \n",
    "    # paper says  : \"last model obtained is infact the best model therefore via hillclimbing we choose this.\"\n",
    "    model_n_neigh = Train(SGDR,model_best,epoch_neigh,lr_start,lr_end)\n",
    "    \n",
    "    #best model on validation set.\n",
    "    \n",
    "    #SELECT MAX ---------------------\n",
    "    \n",
    "    model_best = argMax([ValidationPerformance(model_j) for model_j in models_1__n_neigh])\n",
    "    \n",
    "    #train final model.\n",
    "    model_best = Train(SGDR,model_best,epoch_neigh,lr_start,lr_end)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ApplyNetMorph \n",
    "\n",
    "Algorithm 1 provides full details for the algorithm. In the implementation, the function ApplyNetMorph(model,n) (line 15) applies n network morphisms, each of them sampled uniformly at random from the following three:\n",
    "\n",
    "\n",
    "<img src=\"images/img1.png\" width=500> <img src=\"images/img2.png\" width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 0.5 0.1\n"
     ]
    }
   ],
   "source": [
    "# Testing random number generator bias.\n",
    "\n",
    "cnt = {}\n",
    "\n",
    "cnt[0] = 0\n",
    "cnt[1] = 0 \n",
    "cnt [2] = 0\n",
    "\n",
    "n = 10\n",
    "\n",
    "for _ in range (n) :\n",
    "    cnt[random.choice(range(3))] += 1\n",
    "\n",
    "print cnt[0]/float(n) , cnt[1]/float(n) , cnt[2]/float(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choosen Operation:  <function deepen at 0x11a7a3de8>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def widen(model) :\n",
    "    #sample which conv layer to be widened.\n",
    "    #NetMorph Type 2\n",
    "    #Choose widening faction {2,4} uniformly.\n",
    "    pass\n",
    "\n",
    "def deepen(model) :\n",
    "    #create a Conv-BatchNorm-Relu Block\n",
    "    #Position this block -- 1\n",
    "    #Kernel Size {3,5} -- 2\n",
    "    #Perform 1 & 2 uniformly\n",
    "    \n",
    "    #Number of channels = Channels of closest preceeding channels.\n",
    "    pass\n",
    "\n",
    "\n",
    "def skip_1(model) :\n",
    "    pass\n",
    "\n",
    "def skip_2(model) :\n",
    "    pass\n",
    "\n",
    "skip_operations = [skip_1,skip_2]\n",
    "\n",
    "def skip(model) :\n",
    "    op = skip_operations[random.choice(range(2))]\n",
    "    return op(model)\n",
    "\n",
    "operations = [widen,deepen,skip]\n",
    "\n",
    "def applyMorph(model,n) :\n",
    "    '''\n",
    "    @params :\n",
    "    model : Input Model.\n",
    "    n : Number of network morphisms applied.\n",
    "    '''\n",
    "    \n",
    "    op = operations[random.choice(range(3))]\n",
    "    print 'Choosen Operation: ',op\n",
    "    op(model)\n",
    "    return model\n",
    "\n",
    "applyMorph(0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolutionary ideas presented :\n",
    "\n",
    "While the method is presented as a simple hill-climbing method, it can also be interpreted as a very simple evolutionary algorithm with a population size of n_neigh, no cross-over, network morphisms as mutations, and a selection mechanism that only considers the best-performing population member as the parent for the next generation. This interpretation also suggests several promising possibilities for extending this simple method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
