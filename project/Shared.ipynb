{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed('Mudit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPERIMENTS -- Morphism Type I\n",
    "\n",
    "<img src=\"images/morph1.png\" width=700>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        \"\"\"\n",
    "        In the constructor we construct three nn.Linear instances that we will use\n",
    "        in the forward pass.\n",
    "        \"\"\"\n",
    "        super(Net, self).__init__()\n",
    "        self.inp = D_in\n",
    "        self.out = D_out\n",
    "        self.input_linear = torch.nn.Linear(D_in, H)\n",
    "        self.middle_linear = torch.nn.Linear(H, H)\n",
    "        self.output_linear = torch.nn.Linear(H, D_out)\n",
    "        self.layers = [self.input_linear, self.middle_linear,self.output_linear] \n",
    "        \n",
    "        \n",
    "    \n",
    "    def add_layer(self,pos) :\n",
    "        #insert after pos\n",
    "        #patchwork\n",
    "        #pass from x to pos-1 to get output shape\n",
    "        tempx = torch.randn(1, self.inp)\n",
    "        resx = self.forward(tempx,pause=pos)\n",
    "        print resx.shape\n",
    "        #create pos shaped layer\n",
    "        templayer = torch.nn.Linear(resx.shape[-1],resx.shape[-1])\n",
    "        self.layers.insert(pos,templayer)\n",
    "        \n",
    "        #call for update params\n",
    "\n",
    "   \n",
    "    def forward(self, x,pause=-1):\n",
    "        print 'Layers :',len(self.layers)\n",
    "        \n",
    "        cnt = 0\n",
    "        out = self.layers[0](x)\n",
    "        cnt += 1\n",
    "        if(pause == 1):\n",
    "            return out\n",
    "        \n",
    "        \n",
    "        counter = 1\n",
    "        for layer in self.layers[1:] :\n",
    "            counter+=1\n",
    "            cnt += 1\n",
    "            out = layer(out)\n",
    "            if pause != -1 :\n",
    "                if(counter==pause) :\n",
    "                    print 'Count of Layers = ',cnt\n",
    "                    return out\n",
    "            print 'Count of Layers = ',cnt\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Attempt is to change optimizer dynamically\n",
    "\n",
    "2. Criterion failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=100, out_features=100, bias=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.middle_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((1,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers : 3\n",
      "Count of Layers =  2\n",
      "Count of Layers =  3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers : 3\n",
      "Count of Layers =  2\n",
      "Count of Layers =  3\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1               [-1, 1, 100]         100,100\n",
      "            Linear-2               [-1, 1, 100]          10,100\n",
      "            Linear-3                [-1, 1, 10]           1,010\n",
      "================================================================\n",
      "Total params: 111,210\n",
      "Trainable params: 111,210\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.42\n",
      "Estimated Total Size (MB): 0.43\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = Net(D_in, H, D_out)\n",
    "summary(model,(1,D_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in model.parameters() :\n",
    "#     print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers : 3\n",
      "Count of Layers =  2\n",
      "torch.Size([1, 100])\n",
      "Layers : 4\n",
      "Count of Layers =  2\n",
      "Count of Layers =  3\n",
      "Count of Layers =  4\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1               [-1, 1, 100]         100,100\n",
      "            Linear-2               [-1, 1, 100]          10,100\n",
      "            Linear-3                [-1, 1, 10]           1,010\n",
      "================================================================\n",
      "Total params: 111,210\n",
      "Trainable params: 111,210\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.42\n",
      "Estimated Total Size (MB): 0.43\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.add_layer(2)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9) \n",
    "summary(model,(1,D_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Linear(in_features=1000, out_features=100, bias=True),\n",
       " Linear(in_features=100, out_features=100, bias=True),\n",
       " Linear(in_features=100, out_features=100, bias=True),\n",
       " Linear(in_features=100, out_features=10, bias=True)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers : 3\n",
      "Count of Layers =  2\n",
      "Count of Layers =  3\n",
      "(0, 621.410400390625)\n",
      "Layers : 3\n",
      "Count of Layers =  2\n",
      "Count of Layers =  3\n",
      "(1, 589.3478393554688)\n",
      "Layers : 3\n",
      "Count of Layers =  2\n",
      "Count of Layers =  3\n",
      "(2, 533.2825317382812)\n",
      "Layers : 3\n",
      "Count of Layers =  2\n",
      "Count of Layers =  3\n",
      "(3, 462.329833984375)\n",
      "Layers : 3\n",
      "Count of Layers =  2\n",
      "Count of Layers =  3\n",
      "(4, 384.0874328613281)\n",
      "Layers : 3\n",
      "Count of Layers =  2\n",
      "Count of Layers =  3\n",
      "(5, 304.3170166015625)\n",
      "New optim at work\n",
      "Layers : 3\n",
      "Count of Layers =  2\n",
      "Count of Layers =  3\n",
      "(6, 294.5398864746094)\n",
      "Layers : 3\n",
      "Count of Layers =  2\n",
      "Count of Layers =  3\n",
      "(7, 284.8786315917969)\n",
      "Layers : 3\n",
      "Count of Layers =  2\n",
      "Count of Layers =  3\n",
      "(8, 275.3383483886719)\n",
      "Layers : 3\n",
      "Count of Layers =  2\n",
      "Count of Layers =  3\n",
      "(9, 265.92388916015625)\n"
     ]
    }
   ],
   "source": [
    "model = Net(D_in, H, D_out)\n",
    "\n",
    "\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)\n",
    "\n",
    "num = 10\n",
    "for t in range(num):\n",
    "    y_pred = model(x)\n",
    "    loss = criterion(y_pred, y)\n",
    "    print(t, loss.item())\n",
    "    \n",
    "    if(t==num/2) :\n",
    "        optimizer = torch.optim.Adam(model.parameters(),lr=1e-4)\n",
    "        # with NLL gives certain Long/Float err\n",
    "        print 'New optim at work'\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers : 3\n",
      "Count of Layers =  2\n",
      "Count of Layers =  3\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1               [-1, 1, 100]         100,100\n",
      "            Linear-2               [-1, 1, 100]          10,100\n",
      "            Linear-3                [-1, 1, 10]           1,010\n",
      "================================================================\n",
      "Total params: 111,210\n",
      "Trainable params: 111,210\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.42\n",
      "Estimated Total Size (MB): 0.43\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model,(1,D_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1000])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100])\n",
      "torch.Size([10, 100])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for e in model.parameters() :\n",
    "    print e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Linear(in_features=1000, out_features=100, bias=True),\n",
       " Linear(in_features=100, out_features=100, bias=True),\n",
       " Linear(in_features=100, out_features=10, bias=True)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos = 2\n",
    "# sz = model.forward([1,D_in]).shape[-1]\n",
    "# m = nn.Sequential(for x in model.layers[:pos],nn.Linear(sz,sz),for x in model.layers[pos:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nnet(nn.Module) :\n",
    "    def __init__(self,inp,out) :\n",
    "        super(nnet, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(inp,64)\n",
    "        self.fc2 = nn.Linear(64,128)\n",
    "        self.fc3 = nn.Linear(128,32)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = self.fc1(x)\n",
    "        print 'out1-',out.shape\n",
    "        out = self.fc2(out)\n",
    "        print 'out2-',out.shape\n",
    "        out = self.fc3(out)\n",
    "        print 'out3-',out.shape\n",
    "        return out\n",
    "        \n",
    "        return self.fc3(self.fc2(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out1- torch.Size([2, 1, 64])\n",
      "out2- torch.Size([2, 1, 128])\n",
      "out3- torch.Size([2, 1, 32])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                [-1, 1, 64]           1,088\n",
      "            Linear-2               [-1, 1, 128]           8,320\n",
      "            Linear-3                [-1, 1, 32]           4,128\n",
      "================================================================\n",
      "Total params: 13,536\n",
      "Trainable params: 13,536\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.05\n",
      "Estimated Total Size (MB): 0.05\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model,(1,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nnet(16,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(17,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out1- torch.Size([17, 64])\n",
      "out2- torch.Size([17, 128])\n",
      "out3- torch.Size([17, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([17, 32])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = model(x)\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc1.out_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nnet(\n",
       "  (fc1): Linear(in_features=16, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=32, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc2 = nn.Sequential(nn.Linear(model.fc1.out_features,model.fc1.out_features),model.fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nnet(\n",
       "  (fc1): Linear(in_features=16, out_features=64, bias=True)\n",
       "  (fc2): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (1): Linear(in_features=64, out_features=128, bias=True)\n",
       "  )\n",
       "  (fc3): Linear(in_features=128, out_features=32, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc2[1] = nn.Sequential(model.fc2[1],nn.Linear(model.fc2[1].out_features,model.fc2[1].out_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nnet(\n",
       "  (fc1): Linear(in_features=16, out_features=64, bias=True)\n",
       "  (fc2): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=128, bias=True)\n",
       "      (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (fc3): Linear(in_features=128, out_features=32, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                [-1, 1, 64]           1,088\n",
      "            Linear-2                [-1, 1, 64]           4,160\n",
      "            Linear-3               [-1, 1, 128]           8,320\n",
      "            Linear-4               [-1, 1, 128]          16,512\n",
      "            Linear-5                [-1, 1, 32]           4,128\n",
      "================================================================\n",
      "Total params: 34,208\n",
      "Trainable params: 34,208\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.13\n",
      "Estimated Total Size (MB): 0.13\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model,(1,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc2[0].out_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mechanism required to map all the layers, some sort of dict to call each layer may be stored there itself. We can add a final layer to pytorch module this way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2 -- Network Morph II\n",
    "<img src=\"images/morph2.png\" width=700>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, layer_size, hidden, input_size, output_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.layer_size = layer_size\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.device = 'cpu'\n",
    "\n",
    "        # initialize weights\n",
    "        self.fcs = nn.ModuleList([nn.Linear(self.input_size, self.layer_size)])\n",
    "        self.fcs.append(nn.Linear(self.layer_size, self.output_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        print 'Forward...'\n",
    "        print 'X:',x.shape\n",
    "        print 'weight shapes...'\n",
    "        print 'fcs-0:',self.fcs[0].weight.shape\n",
    "        print 'fcs-1:',self.fcs[1].weight.shape\n",
    "        print 'goes in ', self.fcs[0], 'and gives out'\n",
    "        out = self.fcs[0](x)\n",
    "        print 'out-0:',out.shape, 'and will go in'\n",
    "#         print self.fcs[1]\n",
    "        out = self.fcs[1](out)\n",
    "        print 'out-2:', out.shape\n",
    "#         return self.fcs[1](self.fcs[0](x))\n",
    "    \n",
    "    def add_units(self, addneurons):\n",
    "        # take a copy of the current weights stored in self.fcs\n",
    "        current = [ix.weight.data for ix in self.fcs]\n",
    "        print 'Current:',len(current), ' 1:',current[0].shape,' 2:',current[1].shape\n",
    "\n",
    "        # make the new weights in and out of hidden layer you are adding neurons to\n",
    "        tmp_i = torch.zeros([addneurons, current[0].shape[1]])\n",
    "        print 'tmp_i:',tmp_i.shape\n",
    "        nn.init.xavier_uniform_(tmp_i, gain=nn.init.calculate_gain('relu'))\n",
    "        tmp_o = torch.zeros([current[1].shape[0], addneurons])\n",
    "        print 'tmp_o:',tmp_o.shape\n",
    "        nn.init.xavier_uniform_(tmp_i, gain=nn.init.calculate_gain('relu'))\n",
    "\n",
    "        # concatenate the old weights with the new weights\n",
    "        new_wi = torch.cat([current[0], tmp_i], dim=0)\n",
    "        print 'new_wi:',new_wi.shape\n",
    "        new_wo = torch.cat([current[1], tmp_o], dim=1)\n",
    "        print 'new_wo:',new_wo.shape\n",
    "\n",
    "        # reset weight and grad variables to new size\n",
    "\n",
    "        #TODO------ Pl have a look!\n",
    "        \n",
    "        # should chnage self.layer_size to previous layer's neuron number \n",
    "        self.fcs[0] = nn.Linear(current[0].shape[1], self.layer_size+addneurons)\n",
    "        print 'fcs-0:',self.fcs[0]\n",
    "        self.fcs[1] = nn.Linear(addneurons+self.layer_size, current[1].shape[0])\n",
    "        print 'fcs-1:',self.fcs[1]\n",
    "        \n",
    "        \n",
    "#         self.fcs[0] = nn.Linear(current[0].shape[1], self.layer_size)\n",
    "#         print 'fcs-0:',self.fcs[0]\n",
    "#         self.fcs[1] = nn.Linear(self.layer_size, current[1].shape[0])\n",
    "#         print 'fcs-1:',self.fcs[1]\n",
    "\n",
    "        # set the weight data to new values\n",
    "        self.fcs[0].weight.data = torch.tensor(new_wi, requires_grad=True, device=self.device)\n",
    "        self.fcs[1].weight.data = torch.tensor(new_wo, requires_grad=True, device=self.device)\n",
    "        print 'self.fcs[0] and 1:',self.fcs[0].weight.shape, ' ', self.fcs[1].weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will be buggy when layers increased to 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nm = Model(5,4,3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward...\n",
      "X: torch.Size([1, 3])\n",
      "weight shapes...\n",
      "fcs-0: torch.Size([5, 3])\n",
      "fcs-1: torch.Size([2, 5])\n",
      "goes in  Linear(in_features=3, out_features=5, bias=True) and gives out\n",
      "out-0: torch.Size([1, 5]) and will go in\n",
      "out-2: torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "nm(torch.randn(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current: 2  1: torch.Size([5, 3])  2: torch.Size([2, 5])\n",
      "tmp_i: torch.Size([7, 3])\n",
      "tmp_o: torch.Size([2, 7])\n",
      "new_wi: torch.Size([12, 3])\n",
      "new_wo: torch.Size([2, 12])\n",
      "fcs-0: Linear(in_features=3, out_features=12, bias=True)\n",
      "fcs-1: Linear(in_features=12, out_features=2, bias=True)\n",
      "self.fcs[0] and 1: torch.Size([12, 3])   torch.Size([2, 12])\n"
     ]
    }
   ],
   "source": [
    "nm.add_units(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward...\n",
      "X: torch.Size([1, 3])\n",
      "weight shapes...\n",
      "fcs-0: torch.Size([12, 3])\n",
      "fcs-1: torch.Size([2, 12])\n",
      "goes in  Linear(in_features=3, out_features=12, bias=True) and gives out\n",
      "out-0: torch.Size([1, 12]) and will go in\n",
      "out-2: torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "nm(torch.randn(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward...\n",
      "X: torch.Size([2, 1, 3])\n",
      "weight shapes...\n",
      "fcs-0: torch.Size([12, 3])\n",
      "fcs-1: torch.Size([2, 12])\n",
      "goes in  Linear(in_features=3, out_features=12, bias=True) and gives out\n",
      "out-0: torch.Size([2, 1, 12]) and will go in\n",
      "out-2: torch.Size([2, 1, 2])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                [-1, 1, 12]              48\n",
      "            Linear-2                 [-1, 1, 2]              26\n",
      "================================================================\n",
      "Total params: 74\n",
      "Trainable params: 74\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(nm,(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current: 2  1: torch.Size([12, 3])  2: torch.Size([2, 12])\n",
      "tmp_i: torch.Size([10, 3])\n",
      "tmp_o: torch.Size([2, 10])\n",
      "new_wi: torch.Size([22, 3])\n",
      "new_wo: torch.Size([2, 22])\n",
      "fcs-0: Linear(in_features=3, out_features=15, bias=True)\n",
      "fcs-1: Linear(in_features=15, out_features=2, bias=True)\n",
      "self.fcs[0] and 1: torch.Size([22, 3])   torch.Size([2, 22])\n"
     ]
    }
   ],
   "source": [
    "nm.add_units(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Error Reason listed in the class above, line 52\n",
    "# summary(nm,(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU()\n",
      "ModuleList(\n",
      "  (0): Linear(in_features=3, out_features=15, bias=True)\n",
      "  (1): Linear(in_features=15, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for i in nm.children():\n",
    "    print i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up different learning rates for different layers\n",
    "\n",
    "Advancement over other archs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignored_params = list(map(id, model.fc.parameters()))\n",
    "# base_params = filter(lambda p: id(p) not in ignored_params,\n",
    "#                      model.parameters())\n",
    "\n",
    "# optimizer = torch.optim.SGD([\n",
    "#             {'params': base_params},\n",
    "#             {'params': model.fc.parameters(), 'lr': opt.lr}\n",
    "#         ], lr=opt.lr*0.1, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment -- Network Morphism - III\n",
    "<img src=\"images/morph3.png\" width=700>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read idempotent functions\n",
    "# This implementation involves ReLU support only, as req. by paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NASModuleRELU(nn.Module) :\n",
    "    def __init__(self, input, output):\n",
    "        super(NASModuleRELU, self).__init__()\n",
    "        \n",
    "        self.input = input\n",
    "        self.output = output\n",
    "        \n",
    "        fc1 = nn.Linear(input,32)\n",
    "        fc2 = nn.Linear(32,64)\n",
    "        fc3 = nn.Linear(64,output)\n",
    "\n",
    "        self.layers = [fc1,fc2,fc3]\n",
    "        \n",
    "        self.nns = nn.Sequential(*self.layers)\n",
    "        \n",
    "    def forward(self,x) :\n",
    "        out = self.nns(x)\n",
    "        return out\n",
    "    \n",
    "    def add_relu(self,layer) :\n",
    "        relu = nn.ReLU()\n",
    "        self.layers.insert(layer+1,relu)\n",
    "        self.nns = nn.Sequential(*self.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "relunet = NASModuleRELU(5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                [-1, 1, 32]             192\n",
      "            Linear-2                [-1, 1, 64]           2,112\n",
      "            Linear-3                 [-1, 1, 2]             130\n",
      "================================================================\n",
      "Total params: 2,434\n",
      "Trainable params: 2,434\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.01\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                [-1, 1, 32]             192\n",
      "            Linear-2                [-1, 1, 64]           2,112\n",
      "              ReLU-3                [-1, 1, 64]               0\n",
      "            Linear-4                 [-1, 1, 2]             130\n",
      "================================================================\n",
      "Total params: 2,434\n",
      "Trainable params: 2,434\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.01\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(relunet,(1,5))\n",
    "relunet.add_relu(1)\n",
    "summary(relunet,(1,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4736069904"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(model.fc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment -- Network Morphism IV\n",
    "<img src=\"images/morph4b.png\" width=700>\n",
    "<img src=\"images/morph4a.png\" width=700>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NASModuleSkipConn(nn.Module) :\n",
    "    def __init__(self, input, output):\n",
    "        super(NASModuleRELU, self).__init__()\n",
    "        \n",
    "        self.input = input\n",
    "        self.output = output\n",
    "        \n",
    "        fc1 = nn.Linear(input,32)\n",
    "        fc2 = nn.Linear(32,64)\n",
    "        fc3 = nn.Linear(64,output)\n",
    "\n",
    "        self.layers = [fc1,fc2,fc3]\n",
    "        \n",
    "        self.nns = nn.Sequential(*self.layers)\n",
    "        \n",
    "    def forward(self,x) :\n",
    "        out = self.nns(x)\n",
    "        return out\n",
    "    \n",
    "    def skip_conn(self,layer_i,layer_j) :\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing h(x) is not trivial, atleast from first look."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing NASH\n",
    "\n",
    "<img src=\"images/algo.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total Training epochs => epoch_total = epoch_neigh.n_neigh.n_steps +epoch_final.\n",
    "\n",
    "With the setting \n",
    "\n",
    "n_steps =5\n",
    "\n",
    "epoch_neigh =17\n",
    "\n",
    "epoch_final =100\n",
    "\n",
    "and pretraining the starting network for 20 epochs, the models that are returned by the algorithm are trained for a total number of of 20 + 17 · 5 + 100 = 205 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some start model_0\n",
    "model_0 = 0\n",
    "n_steps = 10\n",
    "n_neigh = 4\n",
    "n_nm = 3\n",
    "epoch_neigh = 30\n",
    "epoch_final = 50\n",
    "lr_start = 0.01\n",
    "lr_end = 0.001  # annealed via SGDR\n",
    "\n",
    "model_best = model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hill climbing\n",
    "\n",
    "for i in range(n_steps) :\n",
    "    \n",
    "    #NEIGHBOURS ---------------------\n",
    "    \n",
    "    # get n_neigh neighbours of model_best\n",
    "    for j in range(n_neigh-1) :\n",
    "        model_j = applyMorph(model_best,n_nm)\n",
    "        \n",
    "        #train this model_j for a few epochs.\n",
    "        \n",
    "        model_j = Train(SGDR,model_j,epoch_neigh,lr_start,lr_end)\n",
    "     \n",
    "    # paper says  : \"last model obtained is infact the best model therefore via hillclimbing we choose this.\"\n",
    "    model_n_neigh = Train(SGDR,model_best,epoch_neigh,lr_start,lr_end)\n",
    "    \n",
    "    #best model on validation set.\n",
    "    \n",
    "    #SELECT MAX ---------------------\n",
    "    \n",
    "    model_best = argMax([ValidationPerformance(model_j) for model_j in models_1__n_neigh])\n",
    "    \n",
    "    #train final model.\n",
    "    model_best = Train(SGDR,model_best,epoch_neigh,lr_start,lr_end)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ApplyNetMorph \n",
    "\n",
    "Algorithm 1 provides full details for the algorithm. In the implementation, the function ApplyNetMorph(model,n) (line 15) applies n network morphisms, each of them sampled uniformly at random from the following three:\n",
    "\n",
    "\n",
    "<img src=\"images/img1.png\" width=500> <img src=\"images/img2.png\" width=500>\n",
    "\n",
    "## Widen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONV WIDEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NASModuleConv(nn.Module) :\n",
    "    def __init__(self, input, output):\n",
    "        super(NASModuleConv, self).__init__()\n",
    "        \n",
    "        self.input = input\n",
    "        self.output = output\n",
    "        \n",
    "        c1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        c2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        c3 = nn.Conv2d(20, 30, kernel_size=5)\n",
    "        \n",
    "        self.layers = [c1,c2,c3]\n",
    "        \n",
    "        self.nns = nn.Sequential(*self.layers)\n",
    "        \n",
    "    def forward(self,x) :\n",
    "        out = self.nns(x)\n",
    "#         out = self.c3(self.c2(self.c1(x)))\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def widen_conv(self, layer,factor):\n",
    "        #affects channels only, no effect on kernel size.\n",
    "        current_layer = self.layers[layer]\n",
    "        next_layer = self.layers[layer+1]\n",
    "#         print 'Current :',current_layer.weight.data.shape, ' & Next :', next_layer.weight.data.shape\n",
    "\n",
    "        orig_channels = current_layer.out_channels\n",
    "\n",
    "        weights = [current_layer.weight.data,next_layer.weight.data]\n",
    "        \n",
    "        current_layer = nn.Conv2d(current_layer.in_channels,\n",
    "                                  current_layer.out_channels*factor,\n",
    "                                  kernel_size=current_layer.kernel_size,\n",
    "                                  stride=current_layer.stride)\n",
    "    \n",
    "        next_layer = nn.Conv2d(current_layer.out_channels,\n",
    "                               next_layer.out_channels,\n",
    "                               kernel_size=next_layer.kernel_size,\n",
    "                               stride=next_layer.stride)\n",
    "        \n",
    "        print current_layer.weight.shape,next_layer.weight.shape\n",
    "    \n",
    "        current_layer.weight.data[0:orig_channels,:] = weights[0]\n",
    "        next_layer.weight.data[:,0:orig_channels] = weights[1]\n",
    "        \n",
    "        self.layers[layer] = current_layer\n",
    "        self.layers[layer+1] = next_layer\n",
    "        \n",
    "        self.nns = nn.Sequential(*self.layers)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 10, 24, 24]             260\n",
      "            Conv2d-2           [-1, 20, 20, 20]           5,020\n",
      "            Conv2d-3           [-1, 30, 16, 16]          15,030\n",
      "================================================================\n",
      "Total params: 20,310\n",
      "Trainable params: 20,310\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.16\n",
      "Params size (MB): 0.08\n",
      "Estimated Total Size (MB): 0.24\n",
      "----------------------------------------------------------------\n",
      "torch.Size([40, 10, 5, 5]) torch.Size([30, 40, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "net = NASModuleConv(1,1)\n",
    "x = torch.randn((5,1,28,28))\n",
    "\n",
    "# print x.shape, net(x).shape\n",
    "summary(net,(1,28,28))\n",
    "\n",
    "# print net.c1.weight.shape\n",
    "# print net.c2.weight.shape\n",
    "# print net.c3.weight.shape\n",
    "\n",
    "net.widen_conv(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 10, 24, 24]             260\n",
      "            Conv2d-2           [-1, 40, 20, 20]          10,040\n",
      "            Conv2d-3           [-1, 30, 16, 16]          30,030\n",
      "================================================================\n",
      "Total params: 40,330\n",
      "Trainable params: 40,330\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.22\n",
      "Params size (MB): 0.15\n",
      "Estimated Total Size (MB): 0.38\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net,(1,28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LINEAR WIDEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NASModule(nn.Module) :\n",
    "    def __init__(self, input, output):\n",
    "        super(NASModule, self).__init__()\n",
    "        \n",
    "        self.input = input\n",
    "        self.output = output\n",
    "        \n",
    "        fc1 = nn.Linear(input,32)\n",
    "        fc2 = nn.Linear(32,64)\n",
    "        fc3 = nn.Linear(64,output)\n",
    "\n",
    "        self.layers = [fc1,fc2,fc3]\n",
    "        \n",
    "        self.nns = nn.Sequential(*self.layers)\n",
    "\n",
    "    def forward(self,x) :\n",
    "        out = self.nns(x)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def widen_linear(self, layer,no_of_neurons):\n",
    "        \n",
    "        # layer = selectLayer(layerNo)\n",
    "#         prev_layer = self.layers[layer-1]\n",
    "        current_layer = self.layers[layer]\n",
    "        next_layer = self.layers[layer+1]\n",
    "        print 'Current :',current_layer.weight.data.shape, ' & Next :', next_layer.weight.data.shape\n",
    "   \n",
    "        I = current_layer.weight.shape[1]\n",
    "        H = current_layer.weight.shape[0]\n",
    "        O = next_layer.weight.shape[0]\n",
    "\n",
    "\n",
    "        weights = [current_layer.weight.data, next_layer.weight.data]\n",
    "        current_layer = torch.nn.Linear(I,H+no_of_neurons)\n",
    "        next_layer = torch.nn.Linear(H+no_of_neurons,O)\n",
    "        current_layer.weight.data[0:-no_of_neurons,:] = weights[0]\n",
    "        next_layer.weight.data[:,0:-no_of_neurons] = weights[1]\n",
    "        \n",
    "        self.layers[layer] = current_layer\n",
    "        self.layers[layer+1] = next_layer\n",
    "        \n",
    "        self.nns = nn.Sequential(*self.layers)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NASModule(10,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1             [-1, 5, 1, 32]             352\n",
      "            Linear-2             [-1, 5, 1, 64]           2,112\n",
      "            Linear-3             [-1, 5, 1, 20]           1,300\n",
      "================================================================\n",
      "Total params: 3,764\n",
      "Trainable params: 3,764\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.02\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net,(5,1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current : torch.Size([64, 32])  & Next : torch.Size([20, 64])\n"
     ]
    }
   ],
   "source": [
    "net.widen_linear(1,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NASModule(\n",
       "  (nns): Sequential(\n",
       "    (0): Linear(in_features=10, out_features=32, bias=True)\n",
       "    (1): Linear(in_features=32, out_features=73, bias=True)\n",
       "    (2): Linear(in_features=73, out_features=20, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1             [-1, 5, 1, 32]             352\n",
      "            Linear-2             [-1, 5, 1, 73]           2,409\n",
      "            Linear-3             [-1, 5, 1, 20]           1,480\n",
      "================================================================\n",
      "Total params: 4,241\n",
      "Trainable params: 4,241\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 0.02\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net,(5,1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((3,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing random number generator bias.\n",
    "\n",
    "cnt = {}\n",
    "\n",
    "cnt[0] = 0\n",
    "cnt[1] = 0 \n",
    "cnt [2] = 0\n",
    "\n",
    "n = 10\n",
    "\n",
    "for _ in range (n) :\n",
    "    cnt[random.choice(range(3))] += 1\n",
    "\n",
    "print cnt[0]/float(n) , cnt[1]/float(n) , cnt[2]/float(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choosen Operation:  <function skip at 0x11b1757d0>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def widen(model) :\n",
    "    #sample which conv layer to be widened.\n",
    "    #NetMorph Type 2\n",
    "    #Choose widening faction {2,4} uniformly.\n",
    "    pass\n",
    "\n",
    "def deepen(model) :\n",
    "    #create a Conv-BatchNorm-Relu Block\n",
    "    #Position this block -- 1\n",
    "    #Kernel Size {3,5} -- 2\n",
    "    #Perform 1 & 2 uniformly\n",
    "    \n",
    "    #Number of channels = Channels of closest preceeding channels.\n",
    "    pass\n",
    "\n",
    "\n",
    "def skip_1(model) :\n",
    "    pass\n",
    "\n",
    "def skip_2(model) :\n",
    "    pass\n",
    "\n",
    "skip_operations = [skip_1,skip_2]\n",
    "\n",
    "def skip(model) :\n",
    "    op = skip_operations[random.choice(range(2))]\n",
    "    return op(model)\n",
    "\n",
    "operations = [widen,deepen,skip]\n",
    "\n",
    "def applyMorph(model,n) :\n",
    "    '''\n",
    "    @params :\n",
    "    model : Input Model.\n",
    "    n : Number of network morphisms applied.\n",
    "    '''\n",
    "    \n",
    "    op = operations[random.choice(range(3))]\n",
    "    print 'Choosen Operation: ',op\n",
    "    op(model)\n",
    "    return model\n",
    "\n",
    "applyMorph(0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolutionary ideas presented :\n",
    "\n",
    "While the method is presented as a simple hill-climbing method, it can also be interpreted as a very simple evolutionary algorithm with a population size of n_neigh, no cross-over, network morphisms as mutations, and a selection mechanism that only considers the best-performing population member as the parent for the next generation. This interpretation also suggests several promising possibilities for extending this simple method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WHAT IF WE APPLY CROSS-OVER AT THE POINT ONE CONV OUTPUT IS SAME AS SOME OTHER CONVE OUTPUT IN PARENT NODE.\n",
    "\n",
    "PROBLEM IS WEIGHT LOSS - BUT ARCHITECTURE MAY IMPROVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
